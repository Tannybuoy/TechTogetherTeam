{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MB_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhtJurmrYC07IYClomY/Ac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catekat16/TechTogetherTeam/blob/ketki/ML%20Model/MB_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VepxZPw4HwQF",
        "outputId": "e645b0e7-77b9-4645-a611-8112bfb5c582"
      },
      "source": [
        "!mkdir .kaggle\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_fzeBsHz0x"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"dazzykin\",\"key\":\"8e623a44cc7443bae9c0b42ca5d093c8\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYS8bcvFIAZ9",
        "outputId": "c0d95fc7-4535-4bd0-fe17-f787cd2a100e"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLwgdAduIEml"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oymh2vTIJFy",
        "outputId": "3a53176e-0d71-4968-ef57-10830a148084"
      },
      "source": [
        "!kaggle datasets download -d datasnaek/mbti-type"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading mbti-type.zip to {/content}/datasets/datasnaek/mbti-type\n",
            " 37% 9.00M/24.4M [00:00<00:01, 9.26MB/s]\n",
            "100% 24.4M/24.4M [00:01<00:00, 24.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVopIH8dIiKP",
        "outputId": "fe160b47-2c74-49c2-bec3-39b014acb352"
      },
      "source": [
        "%cd {/content}/datasets/datasnaek/mbti-type"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/{/content}/datasets/datasnaek/mbti-type\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aKmZ9mvIoeN",
        "outputId": "5f1c62e3-aee0-4252-f8eb-06b5fb0a5220"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  mbti-type.zip\n",
            "  inflating: mbti_1.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKePeGHMkmJq",
        "outputId": "22346cbb-a3d4-4669-94ec-3237437ba0da"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 8.4MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 16.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81701 sha256=dd371b2b141e1987402922538d3bf1173d738594c2870aa68d2693730b92ce0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwb8D8KDLON",
        "outputId": "e32a68f5-b930-4d05-e289-c99122ccdd02"
      },
      "source": [
        "import nltk\n",
        "import contractions\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqMHPIjPTps8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "fj5s7j_QG7Ew",
        "outputId": "9e5ba57a-0c42-42aa-b7db-bd11cf0665c1"
      },
      "source": [
        "corpus = pd.read_csv(\"mbti_1.csv\")\n",
        "corpus.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'I tend to build up a collection of things on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I'm not sure, that's a good question. The dist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce...\n",
              "5  INTJ  '18/37 @.@|||Science  is not perfect. No scien...\n",
              "6  INFJ  'No, I can't draw on my own nails (haha). Thos...\n",
              "7  INTJ  'I tend to build up a collection of things on ...\n",
              "8  INFJ  I'm not sure, that's a good question. The dist...\n",
              "9  INTP  'https://www.youtube.com/watch?v=w8-egj0y8Qs||..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RvSPbX7JNha",
        "outputId": "dcb14c18-5abd-4d24-b964-0a7f1f646397"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU5lQCuVI1_T"
      },
      "source": [
        "#Remove URLs\n",
        "import preprocessor as p\n",
        "corpus['posts'] = corpus['posts'].apply(p.clean)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "oelCJLFjJg7N",
        "outputId": "6fae95b7-6877-4d73-b127-a9c2de0877c9"
      },
      "source": [
        "corpus.head(30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>' and intj moments sportscenter not top ten pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one _____ course, to which I say I know;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP, I enjoyed our conversation the oth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'18/37 .|||Science is not perfect. No scientis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'I tend to build up a collection of things on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>I'm not sure, that's a good question. The dist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>INTP</td>\n",
              "      <td>' in this position where I have to actually le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'One time my parents were fighting over my dad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ENFJ</td>\n",
              "      <td>' |||I went through a break up some months ago...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'Joe santagato - ENTP|||ENFJ or ENTP? I'm not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Fair enough, if that's how you want to look a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Basically this... I has Cheezburgr?|||I am ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Your comment screams INTJ, bro. Especially th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'some of these both excite and calm me: BUTTS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'I think we do agree. I personally don't consi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'I fully believe in the power of being a prote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'That's normal, it happens also to me. If I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Steve Job's was recognized for his striving f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'It is very annoying to be misinterpreted. Esp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'Now I'm interested. But too lazy to go resear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'45016 urh sorry uh. couldn't resist.|||all of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'Still going strong at just over the two year ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'Personally, I was thinking this would be more...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>ENFP</td>\n",
              "      <td>'He doesn't want to go on the trip without me,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ISFP</td>\n",
              "      <td>'They paint without numbers|||I'd guess at ist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'Basically, my main questions are : What do yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'I think that that can absolutely be true of i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    type                                              posts\n",
              "0   INFJ  ' and intj moments sportscenter not top ten pl...\n",
              "1   ENTP  'I'm finding the lack of me in these posts ver...\n",
              "2   INTP  'Good one _____ course, to which I say I know;...\n",
              "3   INTJ  'Dear INTP, I enjoyed our conversation the oth...\n",
              "4   ENTJ  'You're fired.|||That's another silly misconce...\n",
              "5   INTJ  '18/37 .|||Science is not perfect. No scientis...\n",
              "6   INFJ  'No, I can't draw on my own nails (haha). Thos...\n",
              "7   INTJ  'I tend to build up a collection of things on ...\n",
              "8   INFJ  I'm not sure, that's a good question. The dist...\n",
              "9   INTP  ' in this position where I have to actually le...\n",
              "10  INFJ  'One time my parents were fighting over my dad...\n",
              "11  ENFJ  ' |||I went through a break up some months ago...\n",
              "12  INFJ  'Joe santagato - ENTP|||ENFJ or ENTP? I'm not ...\n",
              "13  INTJ  'Fair enough, if that's how you want to look a...\n",
              "14  INTP  'Basically this... I has Cheezburgr?|||I am ve...\n",
              "15  INTP  'Your comment screams INTJ, bro. Especially th...\n",
              "16  INFJ  'some of these both excite and calm me: BUTTS ...\n",
              "17  INFP  'I think we do agree. I personally don't consi...\n",
              "18  INFJ  'I fully believe in the power of being a prote...\n",
              "19  INFP  'That's normal, it happens also to me. If I am...\n",
              "20  INTP  'Steve Job's was recognized for his striving f...\n",
              "21  INFJ  'It is very annoying to be misinterpreted. Esp...\n",
              "22  ENTJ  'Now I'm interested. But too lazy to go resear...\n",
              "23  INFP  '45016 urh sorry uh. couldn't resist.|||all of...\n",
              "24  ENTJ  'Still going strong at just over the two year ...\n",
              "25  INFP  'Personally, I was thinking this would be more...\n",
              "26  ENFP  'He doesn't want to go on the trip without me,...\n",
              "27  ISFP  'They paint without numbers|||I'd guess at ist...\n",
              "28  INFP  'Basically, my main questions are : What do yo...\n",
              "29  INFJ  'I think that that can absolutely be true of i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qh_nsHcKJcu"
      },
      "source": [
        "#Make Everything Lowercase\n",
        "corpus['posts'] =  corpus[\"posts\"].str.lower()\n",
        "corpus['type'] =  corpus[\"type\"].str.lower()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkW-br72ItSQ"
      },
      "source": [
        "# Remove Punctuation and Numbers\n",
        "def remove_punctuations_numbers(text):\n",
        "    punc = string.punctuation +'1234567890' \n",
        "    #print(punc)\n",
        "    for punctuation in punc:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5X0bkQLeKfqi",
        "outputId": "ae066afa-56b0-4746-ffef-f6bc24f43aa9"
      },
      "source": [
        "corpus['posts'] =  corpus[\"posts\"].apply(remove_punctuations_numbers)\n",
        "corpus.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>and intj moments sportscenter not top ten pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>im finding the lack of me in these posts very ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>good one  course to which i say i know thats m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>dear intp i enjoyed our conversation the other...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>youre firedthats another silly misconception t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  infj   and intj moments sportscenter not top ten pla...\n",
              "1  entp  im finding the lack of me in these posts very ...\n",
              "2  intp  good one  course to which i say i know thats m...\n",
              "3  intj  dear intp i enjoyed our conversation the other...\n",
              "4  entj  youre firedthats another silly misconception t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iOxp8h11kRd_",
        "outputId": "dd5b56dd-ad41-4732-9432-b2fcd9575b92"
      },
      "source": [
        "#Remove Word contractions\n",
        "corpus['posts'] =  corpus[\"posts\"].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
        "corpus.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[and, intj, moments, sportscenter, not, top, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, the, lack, of, me, in, these, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, to, which, i, say, i, know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, intp, i, enjoyed, our, conversation, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  infj  [and, intj, moments, sportscenter, not, top, t...\n",
              "1  entp  [I am, finding, the, lack, of, me, in, these, ...\n",
              "2  intp  [good, one, course, to, which, i, say, i, know...\n",
              "3  intj  [dear, intp, i, enjoyed, our, conversation, th...\n",
              "4  entj  [you are, firedthats, another, silly, misconce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EczjUJ9njH2"
      },
      "source": [
        "labels=list(corpus.type.unique())"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulEKRZVCeJQ2"
      },
      "source": [
        "stop_words=set(stopwords.words('english')+labels)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKop-MAS8kS"
      },
      "source": [
        "texts = corpus['posts'].copy()\n",
        "labels = corpus['type'].copy()\n",
        "#texts = [[word for word in text if word not in stop_words] for text in texts]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDhiZnubgzHL"
      },
      "source": [
        "vocab_length=10000"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DUvf3JQMk7xE",
        "outputId": "3fbf5c3d-654b-4ce7-9bd9-06000d85b5c9"
      },
      "source": [
        "#Remove Stop Words\n",
        "corpus['posts'] =  corpus[\"posts\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "corpus.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                              posts\n",
              "0  infj  [moments, sportscenter, top, ten, plays, prank...\n",
              "1  entp  [I am, finding, lack, posts, alarmingsex, bori...\n",
              "2  intp  [good, one, course, say, know, that is, blessi...\n",
              "3  intj  [dear, enjoyed, conversation, day, esoteric, g...\n",
              "4  entj  [you are, firedthats, another, silly, misconce..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bM_qEYEqrI6g",
        "outputId": "f5f6358b-2ccb-4396-fe98-41c9d406b51f"
      },
      "source": [
        "#Clean body Str:\n",
        "corpus['clean_body_str'] = [' '.join(map(str, l)) for l in corpus['posts']]\n",
        "corpus.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                     clean_body_str\n",
              "0  infj  ...  moments sportscenter top ten plays prankswhat ...\n",
              "1  entp  ...  I am finding lack posts alarmingsex boring pos...\n",
              "2  intp  ...  good one course say know that is blessing curs...\n",
              "3  intj  ...  dear enjoyed conversation day esoteric gabbing...\n",
              "4  entj  ...  you are firedthats another silly misconception...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lzgbPMppqxV1",
        "outputId": "65f12364-cf20-45d2-f07b-51615b402523"
      },
      "source": [
        "#Tokenize\n",
        "corpus['tokenized'] = corpus['clean_body_str'].apply(word_tokenize)\n",
        "corpus.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "      <td>[I, am, finding, lack, posts, alarmingsex, bor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "      <td>[good, one, course, say, know, that, is, bless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "      <td>[you, are, firedthats, another, silly, misconc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                          tokenized\n",
              "0  infj  ...  [moments, sportscenter, top, ten, plays, prank...\n",
              "1  entp  ...  [I, am, finding, lack, posts, alarmingsex, bor...\n",
              "2  intp  ...  [good, one, course, say, know, that, is, bless...\n",
              "3  intj  ...  [dear, enjoyed, conversation, day, esoteric, g...\n",
              "4  entj  ...  [you, are, firedthats, another, silly, misconc...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OljeCT1trbgm"
      },
      "source": [
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "efTV7qpnrjP2",
        "outputId": "5a0e4db4-3952-4714-b5a0-c431b04b12cb"
      },
      "source": [
        "#Tagging Parts of Speech in the tokenized \n",
        "corpus['pos_tags'] = corpus['tokenized'].apply(nltk.tag.pos_tag)\n",
        "corpus.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>[(moments, NNS), (sportscenter, VBP), (top, JJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "      <td>[I, am, finding, lack, posts, alarmingsex, bor...</td>\n",
              "      <td>[(I, PRP), (am, VBP), (finding, VBG), (lack, N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "      <td>[good, one, course, say, know, that, is, bless...</td>\n",
              "      <td>[(good, JJ), (one, CD), (course, NN), (say, VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>[(dear, JJ), (enjoyed, JJ), (conversation, NN)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "      <td>[you, are, firedthats, another, silly, misconc...</td>\n",
              "      <td>[(you, PRP), (are, VBP), (firedthats, JJ), (an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                           pos_tags\n",
              "0  infj  ...  [(moments, NNS), (sportscenter, VBP), (top, JJ...\n",
              "1  entp  ...  [(I, PRP), (am, VBP), (finding, VBG), (lack, N...\n",
              "2  intp  ...  [(good, JJ), (one, CD), (course, NN), (say, VB...\n",
              "3  intj  ...  [(dear, JJ), (enjoyed, JJ), (conversation, NN)...\n",
              "4  entj  ...  [(you, PRP), (are, VBP), (firedthats, JJ), (an...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "WI0iAqH6rswi",
        "outputId": "61d7597c-c538-4d9b-9d7d-d28ebd83875c"
      },
      "source": [
        "corpus['wordnet_pos'] = corpus['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
        "corpus.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>[(moments, NNS), (sportscenter, VBP), (top, JJ...</td>\n",
              "      <td>[(moments, n), (sportscenter, v), (top, a), (t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "      <td>[I, am, finding, lack, posts, alarmingsex, bor...</td>\n",
              "      <td>[(I, PRP), (am, VBP), (finding, VBG), (lack, N...</td>\n",
              "      <td>[(I, n), (am, v), (finding, v), (lack, n), (po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "      <td>[good, one, course, say, know, that, is, bless...</td>\n",
              "      <td>[(good, JJ), (one, CD), (course, NN), (say, VB...</td>\n",
              "      <td>[(good, a), (one, n), (course, n), (say, v), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>[(dear, JJ), (enjoyed, JJ), (conversation, NN)...</td>\n",
              "      <td>[(dear, a), (enjoyed, a), (conversation, n), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "      <td>[you, are, firedthats, another, silly, misconc...</td>\n",
              "      <td>[(you, PRP), (are, VBP), (firedthats, JJ), (an...</td>\n",
              "      <td>[(you, n), (are, v), (firedthats, a), (another...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                        wordnet_pos\n",
              "0  infj  ...  [(moments, n), (sportscenter, v), (top, a), (t...\n",
              "1  entp  ...  [(I, n), (am, v), (finding, v), (lack, n), (po...\n",
              "2  intp  ...  [(good, a), (one, n), (course, n), (say, v), (...\n",
              "3  intj  ...  [(dear, a), (enjoyed, a), (conversation, n), (...\n",
              "4  entj  ...  [(you, n), (are, v), (firedthats, a), (another...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA9S8AjOyDKk",
        "outputId": "a9652da5-9390-4344-eaf0-49199be9e75f"
      },
      "source": [
        "print(corpus['clean_body_str'][0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moments sportscenter top ten plays prankswhat lifechanging experience life repeat todaymay perc experience immerse youthe last thing friend posted facebook committing suicide next day rest peace sorry hear distress natural relationship perfection time every moment existence try figure hard times times growth welcome stuff game set matchprozac wellbrutin least thirty minutes moving legs do not mean moving sitting desk chair weed moderation maybe try edibles healthier alternativebasically come three items you have determined type whichever types want would likely use given types cognitive functions whatnot left byall things moderation sims indeed video game good one note good one somewhat subjective completely promoting death given simdear favorite video games growing current favorite video games cool appears late adtheres someone everyonewait thought confidence good thingi cherish time solitude bc revel within inner world whereas time id workin enjoy time do not worry people always around toyo ladies you are complimentary personalitywell hey main social outlet xbox live conversations even verbally fatigue quickly really dig part thread requires meget high backyard roast eat marshmellows backyard conversing something intellectual followed massages kisses many bs sentence could think bbanned watching movies corner duncesbanned health class clearly taught nothing peer pressurebanned whole host reasons two baby deer left right munching beetle middle using blood two cavemen diary todays latest happenings designated cave diary wall see asa pokemon world society everyone becomes optimist artists artists draw idea counts forming something like signaturewelcome robot ranks person downed selfesteem cuz I am avid signature artist like roudbanned taking room bed ya got to learn share roaches much thundering grumbling kind storm yepahh old high school music have not heard ages failed public speaking class years ago I have sort learned could better position big part failure overloading tooi like persons mentality hes confirmed way denver area start new life\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "NkXvL_88r4_0",
        "outputId": "0c22b933-d0bb-443d-e2e8-c2b85f2d7d87"
      },
      "source": [
        "#Lemmatization\n",
        "wnl = WordNetLemmatizer()\n",
        "corpus['lemmatized'] = corpus['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
        "corpus.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>[(moments, NNS), (sportscenter, VBP), (top, JJ...</td>\n",
              "      <td>[(moments, n), (sportscenter, v), (top, a), (t...</td>\n",
              "      <td>[moment, sportscenter, top, ten, play, pranksw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "      <td>[I, am, finding, lack, posts, alarmingsex, bor...</td>\n",
              "      <td>[(I, PRP), (am, VBP), (finding, VBG), (lack, N...</td>\n",
              "      <td>[(I, n), (am, v), (finding, v), (lack, n), (po...</td>\n",
              "      <td>[I, be, find, lack, post, alarmingsex, boring,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "      <td>[good, one, course, say, know, that, is, bless...</td>\n",
              "      <td>[(good, JJ), (one, CD), (course, NN), (say, VB...</td>\n",
              "      <td>[(good, a), (one, n), (course, n), (say, v), (...</td>\n",
              "      <td>[good, one, course, say, know, that, be, bless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>[(dear, JJ), (enjoyed, JJ), (conversation, NN)...</td>\n",
              "      <td>[(dear, a), (enjoyed, a), (conversation, n), (...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "      <td>[you, are, firedthats, another, silly, misconc...</td>\n",
              "      <td>[(you, PRP), (are, VBP), (firedthats, JJ), (an...</td>\n",
              "      <td>[(you, n), (are, v), (firedthats, a), (another...</td>\n",
              "      <td>[you, be, firedthats, another, silly, misconce...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                         lemmatized\n",
              "0  infj  ...  [moment, sportscenter, top, ten, play, pranksw...\n",
              "1  entp  ...  [I, be, find, lack, post, alarmingsex, boring,...\n",
              "2  intp  ...  [good, one, course, say, know, that, be, bless...\n",
              "3  intj  ...  [dear, enjoyed, conversation, day, esoteric, g...\n",
              "4  entj  ...  [you, be, firedthats, another, silly, misconce...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "1t-vHGMhs-dT",
        "outputId": "58d4d615-82c9-4beb-cb32-71e0f34fb65f"
      },
      "source": [
        "#Add Lemma Str column\n",
        "corpus['lemma_str'] = [' '.join(map(str,l)) for l in corpus['lemmatized']]\n",
        "corpus.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>clean_body_str</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>wordnet_pos</th>\n",
              "      <th>lemmatized</th>\n",
              "      <th>lemma_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>infj</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>moments sportscenter top ten plays prankswhat ...</td>\n",
              "      <td>[moments, sportscenter, top, ten, plays, prank...</td>\n",
              "      <td>[(moments, NNS), (sportscenter, VBP), (top, JJ...</td>\n",
              "      <td>[(moments, n), (sportscenter, v), (top, a), (t...</td>\n",
              "      <td>[moment, sportscenter, top, ten, play, pranksw...</td>\n",
              "      <td>moment sportscenter top ten play prankswhat li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entp</td>\n",
              "      <td>[I am, finding, lack, posts, alarmingsex, bori...</td>\n",
              "      <td>I am finding lack posts alarmingsex boring pos...</td>\n",
              "      <td>[I, am, finding, lack, posts, alarmingsex, bor...</td>\n",
              "      <td>[(I, PRP), (am, VBP), (finding, VBG), (lack, N...</td>\n",
              "      <td>[(I, n), (am, v), (finding, v), (lack, n), (po...</td>\n",
              "      <td>[I, be, find, lack, post, alarmingsex, boring,...</td>\n",
              "      <td>I be find lack post alarmingsex boring positio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intp</td>\n",
              "      <td>[good, one, course, say, know, that is, blessi...</td>\n",
              "      <td>good one course say know that is blessing curs...</td>\n",
              "      <td>[good, one, course, say, know, that, is, bless...</td>\n",
              "      <td>[(good, JJ), (one, CD), (course, NN), (say, VB...</td>\n",
              "      <td>[(good, a), (one, n), (course, n), (say, v), (...</td>\n",
              "      <td>[good, one, course, say, know, that, be, bless...</td>\n",
              "      <td>good one course say know that be bless cursedo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intj</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>[(dear, JJ), (enjoyed, JJ), (conversation, NN)...</td>\n",
              "      <td>[(dear, a), (enjoyed, a), (conversation, n), (...</td>\n",
              "      <td>[dear, enjoyed, conversation, day, esoteric, g...</td>\n",
              "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entj</td>\n",
              "      <td>[you are, firedthats, another, silly, misconce...</td>\n",
              "      <td>you are firedthats another silly misconception...</td>\n",
              "      <td>[you, are, firedthats, another, silly, misconc...</td>\n",
              "      <td>[(you, PRP), (are, VBP), (firedthats, JJ), (an...</td>\n",
              "      <td>[(you, n), (are, v), (firedthats, a), (another...</td>\n",
              "      <td>[you, be, firedthats, another, silly, misconce...</td>\n",
              "      <td>you be firedthats another silly misconception ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                          lemma_str\n",
              "0  infj  ...  moment sportscenter top ten play prankswhat li...\n",
              "1  entp  ...  I be find lack post alarmingsex boring positio...\n",
              "2  intp  ...  good one course say know that be bless cursedo...\n",
              "3  intj  ...  dear enjoyed conversation day esoteric gabbing...\n",
              "4  entj  ...  you be firedthats another silly misconception ...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "WHeCzd6vsROP",
        "outputId": "bbc9ec3a-01fb-4b03-8e89-be6897ac4847"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect=None\n",
        "count_vect = CountVectorizer(lowercase=False)\n",
        "X_train_counts = count_vect.fit_transform(corpus['lemma_str'].tolist())\n",
        "X_train_counts.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lemma_str'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3064c0638540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemma_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_train_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'lemma_str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBwpVZTfrijD"
      },
      "source": [
        "Train_X = None\n",
        "Train_Y = None\n",
        "Test_X = None\n",
        "Test_Y = None\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(corpus['lemma_str'],corpus['type'],test_size=0.2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHSN9y2ctkG2"
      },
      "source": [
        "Tfidf_vect=None\n",
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(corpus['lemma_str'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM8pjtI5tyVX"
      },
      "source": [
        "X_train = Train_X_Tfidf\n",
        "Y_train = Train_Y\n",
        "X_test = Test_X_Tfidf\n",
        "Y_test = Test_Y"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDOq7s5NFmjx",
        "outputId": "e3cfad8a-3c42-46f3-8345-136d19c35fc4"
      },
      "source": [
        "print(X_train.shape, Y_train.shape , Y_test.shape, X_test.shape )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6940, 5000) (6940,) (1735,) (1735, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nu7ujoOt91k"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9PGxZMGuJ4D"
      },
      "source": [
        "models = [\n",
        "    svm.SVC(C=1.0, kernel='linear', degree=10, gamma='auto'),\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(),\n",
        "    LogisticRegression(random_state=0)\n",
        "]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEaa3iRquMkD",
        "outputId": "d3524577-720d-44b6-dcb6-4c86959a2468"
      },
      "source": [
        "CV = 3\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "entries = []\n",
        "y_preds=[]\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy*100))\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDz9-8-fuQlL",
        "outputId": "facd447c-1ef1-45a3-df9c-a936d146556d"
      },
      "source": [
        "cv_df.groupby('model_name').accuracy.mean()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_name\n",
              "LinearSVC                 49.855775\n",
              "LogisticRegression        48.659780\n",
              "MultinomialNB             29.351555\n",
              "RandomForestClassifier    22.363115\n",
              "SVC                       49.971115\n",
              "Name: accuracy, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrIOsG9LMPvD"
      },
      "source": [
        "import joblib as jb\n",
        "\n",
        "jb.dump(models[2],\"linearSVC_TTNY.joblib\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs4_ljxbd-9s"
      },
      "source": [
        "!pip freeze >requirements.txt "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}